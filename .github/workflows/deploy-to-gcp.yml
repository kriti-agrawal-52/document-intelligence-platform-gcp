name: Deploy Complete Platform to GCP

on:
  push:
    branches: [main]
  workflow_dispatch:
    inputs:
      force_rebuild_all:
        description: 'Force rebuild all services, even without code changes'
        required: false
        default: 'false'
        type: boolean

env:
  PROJECT_ID: doc-intelligence-1758210325
  REGION: asia-south1
  REPOSITORY: document-intelligence-containers
  CLUSTER_NAME: doc-intel-gke

jobs:
  # Job 1: Infrastructure Setup with Terraform Outputs
  infrastructure:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    outputs:
      mysql_private_ip: ${{ steps.export_tf_outputs.outputs.mysql_private_ip }}
      redis_host: ${{ steps.export_tf_outputs.outputs.redis_host }}
      user_images_bucket: ${{ steps.export_tf_outputs.outputs.user_images_bucket }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Set Terraform environment variables
        run: |
          echo "TF_VAR_gcp_project_id=${{ env.PROJECT_ID }}" >> $GITHUB_ENV
          echo "TF_VAR_gcp_region=${{ env.REGION }}" >> $GITHUB_ENV
          echo "TF_VAR_cluster_name=${{ env.CLUSTER_NAME }}" >> $GITHUB_ENV
          echo "TF_VAR_openai_api_key=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV
          echo "TF_VAR_jwt_secret_key=${{ secrets.JWT_SECRET_KEY }}" >> $GITHUB_ENV
          echo "TF_VAR_mysql_password=${{ secrets.MYSQL_PASSWORD }}" >> $GITHUB_ENV

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init

      - name: Terraform Plan
        working-directory: ./terraform
        run: |
          echo "🔍 Planning infrastructure changes..."
          terraform plan -out=tfplan
          echo "📋 Plan complete. Terraform will only modify what's different from current state."

      - name: Terraform Apply
        working-directory: ./terraform
        run: |
          echo "🚀 Applying infrastructure changes (declarative - only diffs)..."
          terraform apply -auto-approve tfplan
          echo "✅ Infrastructure apply complete"

      - name: Export Terraform Outputs
        id: export_tf_outputs
        working-directory: ./terraform
        run: |
          echo "📋 Exporting infrastructure values for application deployment..."
          echo "mysql_private_ip=$(terraform output -raw mysql_private_ip)" >> $GITHUB_OUTPUT
          echo "redis_host=$(terraform output -raw redis_host)" >> $GITHUB_OUTPUT
          echo "user_images_bucket=$(terraform output -raw user_images_bucket)" >> $GITHUB_OUTPUT
          echo "✅ Infrastructure outputs exported"

  # Job 2: Build, Push, and Deploy Application
  deploy:
    runs-on: ubuntu-latest
    needs: [infrastructure]
    permissions:
      contents: read
      id-token: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Required for accurate git diff analysis

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install GKE Auth Plugin
        run: gcloud components install gke-gcloud-auth-plugin --quiet

      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev

      - name: Get GKE credentials
        run: |
          gcloud container clusters get-credentials ${{ env.CLUSTER_NAME }} \
            --region ${{ env.REGION }} --project ${{ env.PROJECT_ID }}

      - name: Enhanced Smart Rebuild Logic
        id: check_changes
        run: |
          echo "🔍 Analyzing changes for intelligent rebuild decisions..."
          
          # Get changed files with proper handling of different trigger types
          if [[ "${{ github.event_name }}" == "push" ]] && [[ -n "${{ github.event.before }}" ]]; then
            CHANGED_FILES=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }})
          else
            echo "Manual trigger or first commit - checking last commit for changes."
            CHANGED_FILES=$(git diff --name-only HEAD~1 HEAD 2>/dev/null || echo "")
          fi
          
          echo "📋 Changed files:"
          echo "$CHANGED_FILES"
          
          # Check if infrastructure exists (force rebuild if missing)
          echo "🔍 Checking infrastructure and image existence..."
          CLUSTER_EXISTS=$(gcloud container clusters list --filter="name:${{ env.CLUSTER_NAME }}" --format="value(name)" | wc -l)
          AUTH_IMAGE_EXISTS=$(gcloud artifacts docker images list ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/auth-service --limit=1 --format="value(package)" | wc -l)
          EXTRACTION_IMAGE_EXISTS=$(gcloud artifacts docker images list ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-extraction-service --limit=1 --format="value(package)" | wc -l)
          SUMMARIZATION_IMAGE_EXISTS=$(gcloud artifacts docker images list ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-summarization-service --limit=1 --format="value(package)" | wc -l)
          FRONTEND_IMAGE_EXISTS=$(gcloud artifacts docker images list ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend --limit=1 --format="value(package)" | wc -l)
          
          echo "📋 Infrastructure status:"
          echo "  - GKE Cluster exists: $([[ $CLUSTER_EXISTS -gt 0 ]] && echo "✅ Yes" || echo "❌ No")"
          echo "  - Auth image exists: $([[ $AUTH_IMAGE_EXISTS -gt 0 ]] && echo "✅ Yes" || echo "❌ No")"
          echo "  - Extraction image exists: $([[ $EXTRACTION_IMAGE_EXISTS -gt 0 ]] && echo "✅ Yes" || echo "❌ No")"
          echo "  - Summarization image exists: $([[ $SUMMARIZATION_IMAGE_EXISTS -gt 0 ]] && echo "✅ Yes" || echo "❌ No")"
          echo "  - Frontend image exists: $([[ $FRONTEND_IMAGE_EXISTS -gt 0 ]] && echo "✅ Yes" || echo "❌ No")"
          
          # Enhanced function to check service changes with precision and completeness
          check_service_intelligent() {
            local service_path=$1
            local service_name=$2
            local image_exists=$3
            
            echo "🔍 Analyzing $service_name for rebuild necessity..."
            
            # Force rebuild if manual override
            if [[ "${{ github.event.inputs.force_rebuild_all }}" == "true" ]]; then
              echo "🔄 Force rebuild enabled for ${service_name}"
              echo "${service_name}_CHANGED=true" >> $GITHUB_OUTPUT
              return
            fi
            
            # Force rebuild if image doesn't exist (infrastructure-aware)
            if [[ $image_exists -eq 0 ]]; then
              echo "🔄 ${service_name} image missing - forcing rebuild"
              echo "${service_name}_CHANGED=true" >> $GITHUB_OUTPUT
              return
            fi
            
            # Check for relevant code changes (PRECISION - only meaningful files)
            local service_changed=false
            
            # Service-specific source files (excludes README, docs, comments-only changes)
            if echo "$CHANGED_FILES" | grep -qE "^${service_path}/.*\.(py|txt|yml|yaml|json|toml|cfg|ini|sh|js|jsx|ts|tsx|css|scss|html)$|^${service_path}/Dockerfile$|^${service_path}/requirements\.txt$|^${service_path}/package\.json$|^${service_path}/package-lock\.json$|^${service_path}/yarn\.lock$"; then
              echo "✅ Source code changes detected in ${service_name}"
              service_changed=true
            fi
            
            # Check shared dependencies (COMPLETENESS - cross-cutting concerns)
            if echo "$CHANGED_FILES" | grep -qE "^shared/.*\.(py|txt|yml|yaml|json|js|jsx|ts|tsx)$|^config\.yml$|^docker-compose\.yml$"; then
              echo "✅ Shared code changes detected - affects ${service_name}"
              service_changed=true
            fi
            
            # Service-specific shared dependencies
            case $service_name in
              "AUTH"|"EXTRACTION"|"SUMMARIZATION")
                if echo "$CHANGED_FILES" | grep -qE "^shared/(auth_utils|config|database|jwt_blacklist)\.py$"; then
                  echo "✅ Backend shared utilities changed - affects ${service_name}"
                  service_changed=true
                fi
                ;;
              "FRONTEND")
                if echo "$CHANGED_FILES" | grep -qE "^shared/.*\.(ts|tsx|js|jsx|css|scss)$|^frontend/(lib|components|utils)/.*\.(ts|tsx|js|jsx)$"; then
                  echo "✅ Frontend shared components changed - affects ${service_name}"
                  service_changed=true
                fi
                ;;
            esac
            
            # Set final decision
            if [[ $service_changed == true ]]; then
              echo "✅ ${service_name} will be rebuilt"
              echo "${service_name}_CHANGED=true" >> $GITHUB_OUTPUT
            else
              echo "⏭️ No relevant changes for ${service_name} - skipping rebuild"
              echo "${service_name}_CHANGED=false" >> $GITHUB_OUTPUT
            fi
          }
          
          # Analyze each service with intelligent logic
          check_service_intelligent "user_auth" "AUTH" $AUTH_IMAGE_EXISTS
          check_service_intelligent "text_extraction" "EXTRACTION" $EXTRACTION_IMAGE_EXISTS
          check_service_intelligent "text_summarization" "SUMMARIZATION" $SUMMARIZATION_IMAGE_EXISTS
          check_service_intelligent "frontend" "FRONTEND" $FRONTEND_IMAGE_EXISTS
          
          # Special case: Kubernetes manifests change = redeploy (but not rebuild)
          if echo "$CHANGED_FILES" | grep -qE "^kubernetes/.*\.ya?ml$"; then
            echo "🔄 Kubernetes manifests changed - will redeploy all services"
            echo "DEPLOY_CHANGED=true" >> $GITHUB_OUTPUT
          else
            echo "DEPLOY_CHANGED=false" >> $GITHUB_OUTPUT
          fi
          
          echo "📋 Smart rebuild analysis complete"

      # --- Intelligent Build Steps (Only Build What Changed) ---
      - name: Build and push Auth Service
        if: steps.check_changes.outputs.AUTH_CHANGED == 'true'
        run: |
          echo "🔨 Building Auth Service (changes detected)..."
          docker build -f user_auth/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/auth-service:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/auth-service:latest .
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/auth-service
          echo "✅ Auth Service built and pushed"

      - name: Skip Auth Service build
        if: steps.check_changes.outputs.AUTH_CHANGED == 'false'
        run: echo "⏭️ Skipping Auth Service build (no relevant changes)"

      - name: Build and push Text Extraction Service
        if: steps.check_changes.outputs.EXTRACTION_CHANGED == 'true'
        run: |
          echo "🔨 Building Text Extraction Service (changes detected)..."
          docker build -f text_extraction/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-extraction-service:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-extraction-service:latest .
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-extraction-service
          echo "✅ Text Extraction Service built and pushed"

      - name: Skip Text Extraction build
        if: steps.check_changes.outputs.EXTRACTION_CHANGED == 'false'
        run: echo "⏭️ Skipping Text Extraction build (no relevant changes)"

      - name: Build and push Text Summarization Service
        if: steps.check_changes.outputs.SUMMARIZATION_CHANGED == 'true'
        run: |
          echo "🔨 Building Text Summarization Service (changes detected)..."
          docker build -f text_summarization/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-summarization-service:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-summarization-service:latest .
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-summarization-service
          echo "✅ Text Summarization Service built and pushed"

      - name: Skip Text Summarization build
        if: steps.check_changes.outputs.SUMMARIZATION_CHANGED == 'false'
        run: echo "⏭️ Skipping Text Summarization build (no relevant changes)"

      - name: Build and push Frontend
        if: steps.check_changes.outputs.FRONTEND_CHANGED == 'true'
        run: |
          echo "🔨 Building Frontend (changes detected)..."
          docker build -f frontend/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend:latest .
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend
          echo "✅ Frontend built and pushed"

      - name: Skip Frontend build
        if: steps.check_changes.outputs.FRONTEND_CHANGED == 'false'
        run: echo "⏭️ Skipping Frontend build (no relevant changes)"

      # --- Infrastructure-Aware Kubernetes Setup ---
      - name: Setup Kubernetes Foundation and Secrets
        run: |
          echo "🚀 Phase 1: Kubernetes Foundation"
          
          # Apply namespace
          echo "Creating namespace..."
          kubectl apply -f kubernetes/00-namespace.yaml
          
          # Create secrets using Terraform outputs and GitHub Secrets (idempotent)
          echo "🔐 Creating/updating secrets from Terraform outputs and GitHub Secrets..."
          
          kubectl create secret generic db-credentials \
            --namespace=doc-intel-app \
            --from-literal=MYSQL_HOST="${{ needs.infrastructure.outputs.mysql_private_ip }}" \
            --from-literal=MYSQL_USER="${{ secrets.MYSQL_USER }}" \
            --from-literal=MYSQL_PASSWORD="${{ secrets.MYSQL_PASSWORD }}" \
            --from-literal=MYSQL_DATABASE="${{ secrets.MYSQL_DATABASE }}" \
            --from-literal=MYSQL_PORT="3306" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          kubectl create secret generic api-keys \
            --namespace=doc-intel-app \
            --from-literal=JWT_SECRET_KEY="${{ secrets.JWT_SECRET_KEY }}" \
            --from-literal=OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          kubectl create secret generic gcp-config \
            --namespace=doc-intel-app \
            --from-literal=GCP_PROJECT_ID="${{ env.PROJECT_ID }}" \
            --from-literal=GCP_REGION="${{ env.REGION }}" \
            --from-literal=REDIS_HOST="${{ needs.infrastructure.outputs.redis_host }}" \
            --from-literal=REDIS_PORT="6379" \
            --from-literal=GCS_USER_IMAGES_BUCKET="${{ needs.infrastructure.outputs.user_images_bucket }}" \
            --from-literal=PUBSUB_TOPIC_NAME="summarization-jobs" \
            --from-literal=PUBSUB_SUBSCRIPTION_NAME="summarization-jobs-subscription" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          kubectl create secret generic mongodb-credentials \
            --namespace=doc-intel-app \
            --from-literal=MONGODB_HOST="mongodb.doc-intel-app.svc.cluster.local" \
            --from-literal=MONGODB_PORT="27017" \
            --from-literal=MONGODB_DATABASE="document_intelligence" \
            --from-literal=MONGODB_USERNAME="${{ secrets.MONGODB_USERNAME }}" \
            --from-literal=MONGODB_PASSWORD="${{ secrets.MONGODB_PASSWORD }}" \
            --from-literal=MONGODB_COLLECTION_DOCUMENTS="documents" \
            --from-literal=MONGODB_COLLECTION_PROCESSING_JOBS="processing_jobs" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          echo "✅ Secrets created/updated successfully"

      - name: Deploy Database and Dependencies
        run: |
          echo "🚀 Phase 2: Database & Dependencies"
          
          # Deploy MongoDB and database initialization
          echo "Deploying MongoDB..."
          kubectl apply -f kubernetes/04-mongodb-deployment.yaml
          
          echo "Running database initialization..."
          kubectl apply -f kubernetes/05-db-init-job.yaml
          
          echo "✅ Database and dependencies deployed"

      - name: Deploy Application Services
        run: |
          echo "🚀 Phase 3: Application Services"
          
          IMAGE_TAG=${{ github.sha }}
          echo "📦 Deploying applications with unique image tag: $IMAGE_TAG"
          
          # Deploy applications with dynamic image tags (ensures rolling updates)
          echo "Deploying Auth Service..."
          sed "s/IMAGE_TAG_PLACEHOLDER/$IMAGE_TAG/g" kubernetes/06-auth-deployment.yaml | kubectl apply -f -
          
          echo "Deploying Text Extraction Service..."
          sed "s/IMAGE_TAG_PLACEHOLDER/$IMAGE_TAG/g" kubernetes/07-text-extraction-deployment.yaml | kubectl apply -f -
          
          echo "Deploying Text Summarization Service..."
          sed "s/IMAGE_TAG_PLACEHOLDER/$IMAGE_TAG/g" kubernetes/08-text-summarization-deployment.yaml | kubectl apply -f -
          
          echo "✅ Application services deployed"

      - name: Deploy Scaling and Networking
        run: |
          echo "🚀 Phase 4: Auto-scaling & Networking"
          
          # Deploy HPA (Horizontal Pod Autoscaler)
          echo "Configuring auto-scaling..."
          kubectl apply -f kubernetes/09-auth-hpa.yaml
          kubectl apply -f kubernetes/10-text-extraction-hpa.yaml
          kubectl apply -f kubernetes/11-text-summarization-hpa.yaml
          
          # Deploy networking and ingress
          echo "Configuring networking..."
          kubectl apply -f kubernetes/12-backend-config.yaml
          kubectl apply -f kubernetes/13-gcp-ingress.yaml
          
          echo "✅ Scaling and networking configured"

      - name: Wait for Application Readiness
        run: |
          echo "🚀 Phase 5: Deployment Verification"
          echo "⏳ Waiting for deployments to stabilize with new images..."
          
          # Wait for each deployment to be ready (with reasonable timeouts)
          kubectl rollout status deployment/auth-deployment -n doc-intel-app --timeout=10m
          kubectl rollout status deployment/text-extraction-deployment -n doc-intel-app --timeout=10m
          kubectl rollout status deployment/text-summarization-deployment -n doc-intel-app --timeout=10m
          kubectl rollout status deployment/mongodb-deployment -n doc-intel-app --timeout=5m
          
          echo "✅ All deployments successfully rolled out"

      - name: Deploy Frontend to Cloud Run
        run: |
          echo "🚀 Phase 6: Frontend Deployment"
          
          # Get VPC connector for Cloud Run
          VPC_CONNECTOR=$(gcloud compute networks vpc-access connectors list \
            --region=${{ env.REGION }} --format="value(name)" \
            --filter="name:*vpc-connector*" | head -n 1)
          
          if [[ -z "$VPC_CONNECTOR" ]]; then
            echo "⚠️  No VPC connector found - deploying without VPC access"
            VPC_ARGS=""
          else
            echo "🔗 Using VPC Connector: $VPC_CONNECTOR"
            VPC_ARGS="--vpc-connector=$VPC_CONNECTOR --vpc-egress=private-ranges-only"
          fi
          
          # Get internal load balancer IP for frontend configuration
          INTERNAL_LB_IP=$(kubectl get ingress -n doc-intel-app -o jsonpath='{.items[0].status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
          
          if [[ -z "$INTERNAL_LB_IP" ]]; then
            echo "⚠️  Internal LB IP not ready - using placeholder"
            INTERNAL_LB_IP="http://internal-lb-placeholder"
          else
            INTERNAL_LB_IP="http://$INTERNAL_LB_IP"
          fi
          
          # Deploy to Cloud Run
          gcloud run deploy frontend \
            --image=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend:${{ github.sha }} \
            --platform=managed \
            --region=${{ env.REGION }} \
            --allow-unauthenticated \
            --port=3000 \
            --memory=1Gi \
            --cpu=1 \
            --min-instances=0 \
            --max-instances=10 \
            $VPC_ARGS \
            --set-env-vars="NEXT_PUBLIC_AUTH_SERVICE_URL=$INTERNAL_LB_IP,NEXT_PUBLIC_EXTRACTION_SERVICE_URL=$INTERNAL_LB_IP,NEXT_PUBLIC_SUMMARIZATION_SERVICE_URL=$INTERNAL_LB_IP"
          
          echo "✅ Frontend deployed to Cloud Run"

      - name: Final Verification and Health Checks
        run: |
          echo "🚀 Phase 7: Final Verification"
          
          echo "📋 Deployment Summary:"
          echo "===================="
          kubectl get deployments -n doc-intel-app
          echo ""
          echo "📋 Pod Status:"
          echo "=============="
          kubectl get pods -n doc-intel-app
          echo ""
          echo "📋 Services:"
          echo "============"
          kubectl get services -n doc-intel-app
          echo ""
          echo "📋 Ingress:"
          echo "==========="
          kubectl get ingress -n doc-intel-app
          echo ""
          
          # Get Cloud Run URL
          FRONTEND_URL=$(gcloud run services describe frontend --region=${{ env.REGION }} --format="value(status.url)")
          echo "🌐 Frontend URL: $FRONTEND_URL"
          
          echo "✅ Document Intelligence Platform deployed successfully!"
          echo "🎉 All services are running and ready for use"
