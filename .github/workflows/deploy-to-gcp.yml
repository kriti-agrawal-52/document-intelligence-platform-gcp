name: Deploy Complete Platform to GCP

on:
  push:
    branches: [main]
  workflow_dispatch:  # Allow manual triggering
    inputs:
      skip_infrastructure:
        description: 'Skip infrastructure deployment (if already exists)'
        required: false
        default: 'false'
        type: boolean

env:
  PROJECT_ID: doc-intelligence-1758210325
  REGION: asia-south1
  REPOSITORY: document-intelligence-containers
  CLUSTER_NAME: doc-intel-gke

jobs:
  # Job 1: Infrastructure Setup
  infrastructure:
    runs-on: ubuntu-latest
    if: github.event.inputs.skip_infrastructure != 'true'
    
    permissions:
      contents: read
      id-token: write

    outputs:
      cluster_exists: ${{ steps.check_cluster.outputs.exists }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install GKE Auth Plugin
        run: |
          echo "üîß Installing GKE authentication plugin..."
          gcloud components install gke-gcloud-auth-plugin --quiet

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.5.0

      - name: Set Terraform environment variables
        run: |
          echo "TF_VAR_gcp_project_id=${{ env.PROJECT_ID }}" >> $GITHUB_ENV
          echo "TF_VAR_gcp_region=${{ env.REGION }}" >> $GITHUB_ENV
          echo "TF_VAR_project_name=document-intelligence" >> $GITHUB_ENV
          echo "TF_VAR_environment=dev" >> $GITHUB_ENV
          echo "TF_VAR_cluster_name=${{ env.CLUSTER_NAME }}" >> $GITHUB_ENV
          echo "TF_VAR_openai_api_key=${{ secrets.OPENAI_API_KEY }}" >> $GITHUB_ENV
          echo "TF_VAR_jwt_secret_key=${{ secrets.JWT_SECRET_KEY }}" >> $GITHUB_ENV
          echo "TF_VAR_mysql_password=${{ secrets.MYSQL_PASSWORD }}" >> $GITHUB_ENV

      - name: Check if cluster exists
        id: check_cluster
        run: |
          if gcloud container clusters describe ${{ env.CLUSTER_NAME }} --region=${{ env.REGION }} --project=${{ env.PROJECT_ID }} 2>/dev/null; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ GKE cluster already exists, will update if needed"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "üöÄ GKE cluster does not exist, will create"
          fi

      - name: Terraform Init
        run: |
          cd terraform
          terraform init

      - name: Terraform Plan
        run: |
          cd terraform
          echo "üîç Planning infrastructure changes..."
          terraform plan -out=tfplan
          echo "üìã Plan complete. Terraform will only modify what's different from current state."

      - name: Terraform Apply
        run: |
          cd terraform
          echo "üöÄ Applying infrastructure changes (declarative - only diffs)..."
          terraform apply tfplan
          echo "‚úÖ Infrastructure apply complete"

      - name: Verify Infrastructure in VPC
        run: |
          echo "üîç Verifying infrastructure resources exist in VPC..."
          
          # Check VPC exists
          gcloud compute networks describe document-intelligence-vpc --project=${{ env.PROJECT_ID }} || exit 1
          echo "‚úÖ VPC network exists"
          
          # Check GKE cluster is in our VPC  
          CLUSTER_NETWORK=$(gcloud container clusters describe ${{ env.CLUSTER_NAME }} --region=${{ env.REGION }} --project=${{ env.PROJECT_ID }} --format="value(network)")
          if [[ "$CLUSTER_NETWORK" == *"document-intelligence-vpc"* ]]; then
            echo "‚úÖ GKE cluster is in correct VPC"
          else
            echo "‚ùå GKE cluster VPC mismatch: $CLUSTER_NETWORK"
            exit 1
          fi
          
          # Check Cloud SQL is accessible
          gcloud sql instances describe doc-intel-mysql --project=${{ env.PROJECT_ID }} || echo "‚ö†Ô∏è Cloud SQL not found (might be external)"
          
          echo "‚úÖ All infrastructure verified in VPC"

      - name: Setup Kubernetes Foundation
        run: |
          # Get cluster credentials
          echo "üîó Connecting to GKE cluster..."
          gcloud container clusters get-credentials ${{ env.CLUSTER_NAME }} \
            --region ${{ env.REGION }} \
            --project ${{ env.PROJECT_ID }}
          
          # Verify cluster connectivity
          echo "üîç Verifying cluster connectivity..."
          kubectl cluster-info
          kubectl get nodes
          
          # Apply Kubernetes foundation in proper order (declarative)
          echo "üöÄ Phase 1: Foundation (declarative - only applies changes)"
          kubectl apply -f kubernetes/00-namespace.yaml
          
          # Note: External Secrets Operator not needed - using GitHub Secrets for CI/CD
          # This approach is simpler, faster, and saves ~$1/month vs GCP Secret Manager
          # GitHub Secrets provide the same security level with better CI/CD integration
          echo "üîê Using GitHub Secrets for deployment (skipping External Secrets Operator)"
          
          # Use GitHub Secrets directly (more reliable than External Secrets for CI/CD)
          echo "üîê Creating secrets directly from GitHub Secrets (bypassing External Secrets)..."
          
          kubectl create secret generic db-credentials \
            --namespace=doc-intel-app \
            --from-literal=MYSQL_HOST="${{ secrets.MYSQL_HOST }}" \
            --from-literal=MYSQL_USER="${{ secrets.MYSQL_USER }}" \
            --from-literal=MYSQL_PASSWORD="${{ secrets.MYSQL_PASSWORD }}" \
            --from-literal=MYSQL_DATABASE="${{ secrets.MYSQL_DATABASE }}" \
            --from-literal=MYSQL_PORT="3306" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          kubectl create secret generic api-keys \
            --namespace=doc-intel-app \
            --from-literal=OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          # Get infrastructure values directly from GCP for secrets
          echo "üîç Getting infrastructure values from GCP for secrets..."
          REDIS_HOST=$(gcloud redis instances describe document-intelligence-redis --region=asia-south1 --format="value(host)" 2>/dev/null || echo "10.190.0.3")
          REDIS_PORT="6379"
          USER_IMAGES_BUCKET=$(gcloud storage buckets list --filter="name:document-intelligence-user-images" --format="value(name)" 2>/dev/null || echo "document-intelligence-user-images-bucket")
          
          echo "üîç Using infrastructure values for secrets:"
          echo "  REDIS_HOST: $REDIS_HOST"
          echo "  USER_IMAGES_BUCKET: $USER_IMAGES_BUCKET"
          
          # Note: MYSQL_HOST uses Kubernetes service DNS, not direct IP
          kubectl create secret generic db-credentials \
            --namespace=doc-intel-app \
            --from-literal=MYSQL_HOST="mysql-external.doc-intel-app.svc.cluster.local" \
            --from-literal=MYSQL_USER="app_user" \
            --from-literal=MYSQL_PASSWORD="${{ secrets.MYSQL_PASSWORD }}" \
            --from-literal=MYSQL_DATABASE="auth_db" \
            --from-literal=MYSQL_PORT="3306" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          kubectl create secret generic api-keys \
            --namespace=doc-intel-app \
            --from-literal=JWT_SECRET_KEY="${{ secrets.JWT_SECRET_KEY }}" \
            --from-literal=OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          kubectl create secret generic gcp-config \
            --namespace=doc-intel-app \
            --from-literal=GCP_PROJECT_ID="${{ env.PROJECT_ID }}" \
            --from-literal=GCP_REGION="${{ env.REGION }}" \
            --from-literal=REDIS_HOST="$REDIS_HOST" \
            --from-literal=REDIS_PORT="$REDIS_PORT" \
            --from-literal=GCS_USER_IMAGES_BUCKET="$USER_IMAGES_BUCKET" \
            --from-literal=PUBSUB_TOPIC_NAME="summarization-jobs" \
            --from-literal=PUBSUB_SUBSCRIPTION_NAME="summarization-jobs-subscription" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          kubectl create secret generic mongodb-credentials \
            --namespace=doc-intel-app \
            --from-literal=MONGODB_USER="${{ secrets.MONGODB_USER }}" \
            --from-literal=MONGODB_PASSWORD="${{ secrets.MONGODB_PASSWORD }}" \
            --from-literal=MONGO_CONNECTION_STRING="mongodb://${{ secrets.MONGODB_USER }}:${{ secrets.MONGODB_PASSWORD }}@mongodb-service:27017/doc_intel_db?authSource=admin" \
            --from-literal=MONGO_DATABASE_NAME="doc_intel_db" \
            --from-literal=MONGO_COLLECTION_NAME="extracted_texts" \
            --dry-run=client -o yaml | kubectl apply -f -
          
          echo "‚úÖ All secrets created successfully from GitHub Secrets"
          
          # Wait for namespace to be ready (with better error handling)
          echo "‚è≥ Waiting for namespace to be active..."
          if kubectl wait --for=condition=Active --timeout=60s namespace/doc-intel-app; then
            echo "‚úÖ Namespace is active"
          else
            echo "‚ö†Ô∏è Namespace wait timed out, checking status..."
            kubectl get namespace doc-intel-app -o yaml
            kubectl describe namespace doc-intel-app
            echo "Continuing anyway - namespace likely exists..."
          fi
          
          echo "üöÄ Phase 2: Storage & Dependencies"
          
          # Get MySQL IP directly from GCP and inject into manifest
          echo "üîç Getting MySQL IP from GCP Cloud SQL..."
          export MYSQL_PRIVATE_IP=$(gcloud sql instances describe document-intelligence-mysql-swzt --format="value(ipAddresses[0].ipAddress)" 2>/dev/null || echo "10.190.1.3")
          
          echo "üîç Injecting MySQL IP: $MYSQL_PRIVATE_IP into MySQL external service"
          
          # Use envsubst to replace environment variables in the manifest
          envsubst < kubernetes/03-mysql-external-service.yaml > /tmp/mysql-external-service-with-ip.yaml
          
          # Verify the IP was injected correctly
          echo "üìã Generated manifest with actual IP:"
          cat /tmp/mysql-external-service-with-ip.yaml | grep -A 2 -B 2 "ip:"
          
          # Apply the file with the correct IP
          kubectl apply -f /tmp/mysql-external-service-with-ip.yaml
          kubectl apply -f kubernetes/04-mongodb-deployment.yaml
          kubectl apply -f kubernetes/05-db-init-job.yaml
          
          # Check what was actually changed
          echo "üìã Checking deployment status..."
          kubectl get all -n doc-intel-app
          
          # Wait for databases to be ready with better feedback
          echo "‚è≥ Waiting for MongoDB to be ready (up to 5 minutes)..."
          if kubectl wait --for=condition=available --timeout=300s deployment/mongodb-deployment --namespace=doc-intel-app; then
            echo "‚úÖ MongoDB is ready"
          else
            echo "‚ö†Ô∏è MongoDB not ready yet, continuing (will retry in application phase)"
            kubectl describe deployment/mongodb-deployment -n doc-intel-app
          fi
          
          # Verify foundation resources
          echo "üîç Verifying foundation resources..."
          kubectl get secrets -n doc-intel-app
          kubectl get services -n doc-intel-app
          
          echo "‚úÖ Infrastructure and foundation setup complete"

  # Job 2: Application Deployment  
  deploy:
    runs-on: ubuntu-latest
    needs: [infrastructure]  # Wait for infrastructure to complete
    if: always() && (needs.infrastructure.result == 'success' || github.event.inputs.skip_infrastructure == 'true')
    
    permissions:
      contents: read
      id-token: write  # For Workload Identity Federation

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Install GKE Auth Plugin
        run: |
          echo "üîß Installing GKE authentication plugin..."
          gcloud components install gke-gcloud-auth-plugin --quiet

      - name: Configure Docker for Artifact Registry
        run: gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev

      - name: Check for code changes (Smart Rebuild Logic)
        id: check_changes
        run: |
          echo "üîç Checking what changed since last deployment..."
          
          # Check if microservice code changed
          if git diff --name-only HEAD~1 HEAD | grep -E "(user_auth|text_extraction|text_summarization)/" | grep -v "test"; then
            echo "üîÑ Microservice code changed - rebuilding containers"
            echo "AUTH_CHANGED=true" >> $GITHUB_OUTPUT
            echo "EXTRACTION_CHANGED=true" >> $GITHUB_OUTPUT  
            echo "SUMMARIZATION_CHANGED=true" >> $GITHUB_OUTPUT
          else
            echo "‚úÖ No microservice code changes - using existing v1 images"
            echo "AUTH_CHANGED=false" >> $GITHUB_OUTPUT
            echo "EXTRACTION_CHANGED=false" >> $GITHUB_OUTPUT
            echo "SUMMARIZATION_CHANGED=false" >> $GITHUB_OUTPUT
          fi
          
          # Check specific service changes for granular rebuilds
          if git diff --name-only HEAD~1 HEAD | grep -q "user_auth/"; then
            echo "AUTH_CHANGED=true" >> $GITHUB_OUTPUT
          fi
          
          if git diff --name-only HEAD~1 HEAD | grep -q "text_extraction/"; then
            echo "EXTRACTION_CHANGED=true" >> $GITHUB_OUTPUT
          fi
          
          if git diff --name-only HEAD~1 HEAD | grep -q "text_summarization/"; then
            echo "SUMMARIZATION_CHANGED=true" >> $GITHUB_OUTPUT
          fi
          
          # Check frontend changes
          if git diff --name-only HEAD~1 HEAD | grep -q "frontend/"; then
            echo "FRONTEND_CHANGED=true" >> $GITHUB_OUTPUT
          else
            echo "FRONTEND_CHANGED=false" >> $GITHUB_OUTPUT
          fi

      - name: Get GKE credentials
        run: |
          gcloud container clusters get-credentials ${{ env.CLUSTER_NAME }} \
            --region ${{ env.REGION }} \
            --project ${{ env.PROJECT_ID }}

      # Smart rebuild: Only build services that changed
      - name: Build and push Auth Service
        if: steps.check_changes.outputs.AUTH_CHANGED == 'true'
        run: |
          echo "üî® Building Auth Service (code changed)"
          docker build -f user_auth/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/auth-service:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/auth-service:v1 .
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/auth-service

      - name: Skip Auth Service build
        if: steps.check_changes.outputs.AUTH_CHANGED == 'false'
        run: echo "‚è≠Ô∏è Skipping Auth Service build (no code changes)"

      - name: Build and push Text Extraction Service
        if: steps.check_changes.outputs.EXTRACTION_CHANGED == 'true'
        run: |
          echo "üî® Building Text Extraction Service (code changed)"
          docker build -f text_extraction/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-extraction-service:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-extraction-service:v1 .
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-extraction-service

      - name: Skip Text Extraction build
        if: steps.check_changes.outputs.EXTRACTION_CHANGED == 'false'
        run: echo "‚è≠Ô∏è Skipping Text Extraction build (no code changes)"

      - name: Build and push Text Summarization Service
        if: steps.check_changes.outputs.SUMMARIZATION_CHANGED == 'true'
        run: |
          echo "üî® Building Text Summarization Service (code changed)"
          docker build -f text_summarization/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-summarization-service:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-summarization-service:v1 .
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/text-summarization-service

      - name: Skip Text Summarization build
        if: steps.check_changes.outputs.SUMMARIZATION_CHANGED == 'false'
        run: echo "‚è≠Ô∏è Skipping Text Summarization build (no code changes)"

      - name: Build and push Frontend
        if: steps.check_changes.outputs.FRONTEND_CHANGED == 'true'
        run: |
          echo "üî® Building Frontend (code changed)"
          docker build -f frontend/Dockerfile \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend:${{ github.sha }} \
            -t ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend:v1 ./frontend
          docker push --all-tags ${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend

      - name: Skip Frontend build
        if: steps.check_changes.outputs.FRONTEND_CHANGED == 'false'
        run: echo "‚è≠Ô∏è Skipping Frontend build (no code changes)"

      - name: Clean up old SHA-tagged images (cost optimization)
        run: |
          echo "üßπ Cleaning up old SHA-tagged images from Artifact Registry..."
          
          # Keep only the last 5 SHA-tagged images for each service (cost optimization)
          for service in auth-service text-extraction-service text-summarization-service frontend; do
            echo "Cleaning up old $service images..."
            gcloud artifacts docker images list asia-south1-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/$service \
              --include-tags --sort-by=~CREATE_TIME --format="value(version)" | \
              grep -E "^[a-f0-9]{40}$" | tail -n +6 | \
              xargs -I {} gcloud artifacts docker images delete \
                asia-south1-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/$service:{} --quiet || true
          done
          
          echo "‚úÖ Old images cleaned up - keeping v1 tags and recent 5 SHA tags"

      # Deploy Kubernetes manifests
      - name: Install External Secrets Operator
        run: |
          # Install External Secrets Operator using Helm
          helm repo add external-secrets https://charts.external-secrets.io
          helm repo update
          helm upgrade --install external-secrets external-secrets/external-secrets \
            --namespace external-secrets-system \
            --create-namespace \
            --wait

      - name: Deploy Kubernetes resources
        run: |
          # Apply Kubernetes manifests in order
          kubectl apply -f kubernetes/00-namespace.yaml
          
          # Wait for External Secrets Operator to be ready
          kubectl wait --for=condition=available --timeout=300s deployment/external-secrets -n external-secrets-system
          kubectl wait --for=condition=available --timeout=300s deployment/external-secrets-webhook -n external-secrets-system
          kubectl wait --for=condition=available --timeout=300s deployment/external-secrets-cert-controller -n external-secrets-system
          
          # Wait for CRDs to be available
          echo "Waiting for External Secrets CRDs to be available..."
          for i in {1..30}; do
            if kubectl get crd secretstores.external-secrets.io externalsecrets.external-secrets.io &>/dev/null; then
              echo "CRDs are available!"
              break
            fi
            echo "Waiting for CRDs... ($i/30)"
            sleep 10
          done
          
          # Verify CRDs exist and check their versions
          kubectl get crd secretstores.external-secrets.io
          kubectl get crd externalsecrets.external-secrets.io
          
          # Check CRD details and available versions
          echo "Checking SecretStore CRD versions..."
          kubectl get crd secretstores.external-secrets.io -o jsonpath='{.spec.versions[*].name}' || true
          echo ""
          echo "Checking ExternalSecret CRD versions..."
          kubectl get crd externalsecrets.external-secrets.io -o jsonpath='{.spec.versions[*].name}' || true
          echo ""
          
          # Wait a bit more for API server to fully register the CRDs
          echo "Waiting additional time for API server to register CRDs..."
          sleep 30
          
          # Test if we can access the API
          kubectl api-resources | grep external-secrets || true
          
          # Try to apply External Secrets configuration, fallback to regular secrets if it fails
          if ! kubectl apply -f kubernetes/01-external-secrets.yaml; then
            echo "External Secrets failed, falling back to regular Kubernetes secrets..."
            echo "Creating secrets from GitHub secrets..."
            
            # Create secrets using GitHub secrets
            kubectl create secret generic db-credentials \
              --namespace=doc-intel-app \
              --from-literal=MYSQL_USER="app_user" \
              --from-literal=MYSQL_PASSWORD="${{ secrets.MYSQL_PASSWORD }}" \
              --from-literal=MYSQL_HOST="10.20.0.5" \
              --from-literal=MYSQL_PORT="3306" \
              --dry-run=client -o yaml | kubectl apply -f -
            
            kubectl create secret generic api-keys \
              --namespace=doc-intel-app \
              --from-literal=JWT_SECRET_KEY="${{ secrets.JWT_SECRET_KEY }}" \
              --from-literal=OPENAI_API_KEY="${{ secrets.OPENAI_API_KEY }}" \
              --dry-run=client -o yaml | kubectl apply -f -
            
            
            kubectl create secret generic mongodb-credentials \
              --namespace=doc-intel-app \
              --from-literal=MONGODB_USER="${{ secrets.MONGODB_USER }}" \
              --from-literal=MONGODB_PASSWORD="${{ secrets.MONGODB_PASSWORD }}" \
              --from-literal=MONGODB_HOST="mongodb-service" \
              --from-literal=MONGODB_PORT="27017" \
              --from-literal=MONGO_CONNECTION_STRING="mongodb://${{ secrets.MONGODB_USER }}:${{ secrets.MONGODB_PASSWORD }}@mongodb-service:27017/doc_intel_db?authSource=admin" \
              --from-literal=MONGO_DATABASE_NAME="doc_intel_db" \
              --from-literal=MONGO_COLLECTION_NAME="extracted_texts" \
              --dry-run=client -o yaml | kubectl apply -f -
          fi
          # Note: Using 'latest' tags for stable image references (no IMAGE_TAG replacement needed)
          echo "üì¶ Using 'latest' image tags for consistent deployments"
          
          # Apply Kubernetes resources in proper order to avoid race conditions
          echo "üöÄ Phase 1: Foundation & Secrets"
          # Namespace and secrets already applied above
          
          echo "üöÄ Phase 2: Storage & Dependencies"  
          # Note: MySQL external service already applied in infrastructure job with correct IP
          kubectl apply -f kubernetes/04-mongodb-deployment.yaml
          kubectl apply -f kubernetes/05-db-init-job.yaml
          
          echo "üöÄ Phase 3: Application Services"
          kubectl apply -f kubernetes/06-auth-deployment.yaml
          kubectl apply -f kubernetes/07-text-extraction-deployment.yaml
          kubectl apply -f kubernetes/08-text-summarization-deployment.yaml
          
          echo "üöÄ Phase 4: Wait for pods to be ready before ALB"
          kubectl wait --for=condition=available --timeout=300s deployment/auth-deployment --namespace=doc-intel-app
          kubectl wait --for=condition=available --timeout=300s deployment/text-extraction-deployment --namespace=doc-intel-app
          kubectl wait --for=condition=available --timeout=300s deployment/text-summarization-deployment --namespace=doc-intel-app
          
          echo "üöÄ Phase 5: Scaling & Load Balancing (after pods are ready)"
          kubectl apply -f kubernetes/09-auth-hpa.yaml
          kubectl apply -f kubernetes/10-text-extraction-hpa.yaml
          kubectl apply -f kubernetes/11-text-summarization-hpa.yaml
          kubectl apply -f kubernetes/12-backend-config.yaml
          kubectl apply -f kubernetes/13-gcp-ingress.yaml
          
          # Check deployment status before waiting
          echo "Checking deployment status..."
          kubectl get deployments -n doc-intel-app || true
          kubectl get pods -n doc-intel-app || true
          
          # Wait for deployments to be ready (with shorter timeout since images might not be updated yet)
          echo "Waiting for initial deployments (may fail if images not updated yet)..."
          kubectl wait --for=condition=available --timeout=60s deployment/auth-deployment -n doc-intel-app || echo "Auth deployment not ready yet (expected)"
          kubectl wait --for=condition=available --timeout=60s deployment/text-extraction-deployment -n doc-intel-app || echo "Text extraction deployment not ready yet (expected)"
          kubectl wait --for=condition=available --timeout=60s deployment/text-summarization-deployment -n doc-intel-app || echo "Text summarization deployment not ready yet (expected)"

      # Update Kubernetes deployments with new images
      # Deployments are now updated declaratively via kubectl apply above
      # No need for kubectl set image commands - GitOps approach!

      # Wait for updated deployments and debug any issues
      - name: Wait for deployments and debug issues
        run: |
          echo "Waiting for deployments to be ready with new images..."
          
          # Check deployment status
          kubectl get deployments -n doc-intel-app
          kubectl describe deployment auth-deployment -n doc-intel-app
          
          # Check pod status
          kubectl get pods -n doc-intel-app
          
          # Wait for deployments with longer timeout
          kubectl wait --for=condition=available --timeout=600s deployment/auth-deployment -n doc-intel-app || {
            echo "Auth deployment failed, checking logs..."
            kubectl describe deployment auth-deployment -n doc-intel-app
            kubectl get pods -l app=auth-service -n doc-intel-app
            kubectl logs -l app=auth-service -n doc-intel-app --tail=50 || true
          }
          
          kubectl wait --for=condition=available --timeout=300s deployment/text-extraction-deployment -n doc-intel-app || {
            echo "Text extraction deployment failed, checking logs..."
            kubectl logs -l app=text-extraction-service -n doc-intel-app --tail=50 || true
          }
          
          kubectl wait --for=condition=available --timeout=300s deployment/text-summarization-deployment -n doc-intel-app || {
            echo "Text summarization deployment failed, checking logs..."
            kubectl logs -l app=text-summarization-service -n doc-intel-app --tail=50 || true
          }

      # Wait for HTTPS ingress to be fully ready before deploying frontend
      - name: Wait for internal HTTP ingress
        run: |
          echo "‚è≥ Waiting for internal ingress LoadBalancer to be ready..."
          echo "This creates an internal HTTP endpoint for frontend ‚Üí backend communication."
          
          # Wait for internal ingress IP assignment (up to 10 minutes)
          INGRESS_IP=""
          for i in {1..20}; do
            INGRESS_IP=$(kubectl get ingress doc-intel-ingress -n doc-intel-app -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
            if [ ! -z "$INGRESS_IP" ]; then
              echo "‚úÖ Internal Ingress IP assigned: $INGRESS_IP"
              break
            fi
            echo "‚è≥ Waiting for internal ingress IP assignment... ($i/20) - 30s intervals"
            sleep 30
          done
          
          if [ -z "$INGRESS_IP" ]; then
            echo "‚ö†Ô∏è Internal Ingress IP not ready after 10 minutes"
            echo "üìã This is normal for internal load balancers - they may take longer"
            # For internal LB, we'll get the IP from the service or use a placeholder
            INGRESS_IP="10.0.0.100"  # Placeholder for internal IP
          fi
          
          # Test HTTP ingress readiness with extended timeout
          echo "üîç Testing HTTP ingress readiness on $INGRESS_IP..."
          echo "üí° Note: GCP Load Balancer health checks can take 10-15 minutes to propagate"
          
          INGRESS_READY=false
          for i in {1..15}; do
            echo "‚è≥ Waiting for HTTP ingress... ($i/15) - 30s intervals (Total: $((i*30/60)) min)"
            if curl -s -w "%{http_code}" http://$INGRESS_IP/auth/health 2>/dev/null | grep -q "200"; then
              echo "‚úÖ HTTP ingress is ready!"
              INGRESS_READY=true
              break
            fi
            sleep 30
          done
          
          if [ "$INGRESS_READY" = false ]; then
            echo "‚ö†Ô∏è  Ingress not ready after 7.5 minutes, but continuing deployment"
            echo "üîç This is normal for GCP - health checks may take up to 15 minutes"
            echo "üìã Backend health status:"
            kubectl get ingress doc-intel-ingress -n doc-intel-app -o jsonpath='{.metadata.annotations.ingress\.kubernetes\.io/backends}' || true
          fi
          
          # Set environment variable for frontend deployment
          echo "INGRESS_IP=$INGRESS_IP" >> $GITHUB_ENV
          
          # Update ConfigMap with actual internal ingress IP
          echo "üîß Updating ingress ConfigMap with internal IP: $INGRESS_IP"
          kubectl patch configmap ingress-config -n doc-intel-app --type merge -p "{\"data\":{\"backend-url\":\"http://$INGRESS_IP\"}}"

      # Deploy Frontend to Cloud Run with HTTP ingress (development setup)
      - name: Deploy Frontend to Cloud Run
        run: |
          echo "üöÄ Deploying frontend with HTTP backend URLs: http://$INGRESS_IP"
          echo "Note: Using HTTP for development - no SSL complexity"
          # Get VPC connector name from GCP
          VPC_CONNECTOR=$(gcloud compute networks vpc-access connectors list --region=${{ env.REGION }} --format="value(name)" --filter="name:doc-intel-vpc-connector")
          echo "üîó Using VPC Connector: $VPC_CONNECTOR"
          
          gcloud run deploy frontend \
            --image=${{ env.REGION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/frontend:v1 \
            --platform=managed \
            --region=${{ env.REGION }} \
            --allow-unauthenticated \
            --port=3000 \
            --memory=1Gi \
            --cpu=1 \
            --min-instances=0 \
            --max-instances=10 \
            --vpc-connector=$VPC_CONNECTOR \
            --vpc-egress=private-ranges-only \
            --set-env-vars="NEXT_PUBLIC_AUTH_SERVICE_URL=http://$INGRESS_IP,NEXT_PUBLIC_EXTRACTION_SERVICE_URL=http://$INGRESS_IP,NEXT_PUBLIC_SUMMARIZATION_SERVICE_URL=http://$INGRESS_IP"

      # Verify deployments with comprehensive ALB/Ingress debugging
      - name: Verify backend deployments and ALB status
        run: |
          echo "üîç COMPREHENSIVE BACKEND & ALB VERIFICATION"
          echo "=========================================="
          
          # 1. Verify deployment rollout status
          echo "üìã 1. Checking deployment rollout status..."
          kubectl rollout status deployment/auth-deployment --namespace=doc-intel-app --timeout=300s
          kubectl rollout status deployment/text-extraction-deployment --namespace=doc-intel-app --timeout=300s
          kubectl rollout status deployment/text-summarization-deployment --namespace=doc-intel-app --timeout=300s
          
          # 2. Check pod health and readiness
          echo ""
          echo "üè• 2. Pod Health Status:"
          kubectl get pods -n doc-intel-app -o wide
          
          # 3. Check service configurations
          echo ""
          echo "üåê 3. Service Configurations:"
          kubectl get services -n doc-intel-app
          
          # 4. Comprehensive Ingress Debugging
          echo ""
          echo "üîç 4. INGRESS & ALB DEBUGGING:"
          echo "=============================="
          
          # Basic ingress info
          echo "üìã Ingress Basic Info:"
          kubectl get ingress -n doc-intel-app
          
          # Detailed ingress description
          echo ""
          echo "üìã Ingress Detailed Status:"
          kubectl describe ingress doc-intel-ingress -n doc-intel-app
          
          # Backend health status
          echo ""
          echo "‚ù§Ô∏è  Backend Health Status:"
          kubectl get ingress doc-intel-ingress -n doc-intel-app -o jsonpath='{.metadata.annotations.ingress\.kubernetes\.io/backends}' | python3 -c 'import sys, json; input_data = sys.stdin.read().strip(); data = json.loads(input_data) if input_data else {}; [print(f"  - {backend}: {status}") for backend, status in data.items()]' || echo "  Backend status not available yet"
          
          # Check ingress events
          echo ""
          echo "üìã Recent Ingress Events:"
          kubectl get events -n doc-intel-app --field-selector involvedObject.name=doc-intel-ingress --sort-by='.lastTimestamp' | tail -10 || true
          
          # 5. Test connectivity to individual services
          echo ""
          echo "üß™ 5. SERVICE CONNECTIVITY TESTS:"
          echo "================================="
          
          # Get ingress IP
          INGRESS_IP=$(kubectl get ingress doc-intel-ingress -n doc-intel-app -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || gcloud compute addresses describe doc-intel-ip --global --format="value(address)")
          echo "üåê Testing via Ingress IP: $INGRESS_IP"
          
          # Test each service endpoint
          for service in "auth:8000:/auth/health" "extract:8001:/extract/health" "summarize:8002:/summarize/health"; do
            name=$(echo $service | cut -d: -f1)
            path=$(echo $service | cut -d: -f3)
            echo ""
            echo "Testing $name service at $path..."
            
            # Test with detailed curl output
            response=$(curl -s -w "HTTPSTATUS:%{http_code};TIME:%{time_total}" http://$INGRESS_IP$path 2>/dev/null || echo "HTTPSTATUS:000;TIME:timeout")
            http_code=$(echo $response | grep -o "HTTPSTATUS:[0-9]*" | cut -d: -f2)
            time_total=$(echo $response | grep -o "TIME:[0-9.]*" | cut -d: -f2)
            response_body=$(echo $response | sed 's/HTTPSTATUS:[0-9]*;TIME:[0-9.]*//')
            
            if [ "$http_code" = "200" ]; then
              echo "  ‚úÖ $name: HTTP $http_code (${time_total}s) - $response_body"
            else
              echo "  ‚ùå $name: HTTP $http_code (${time_total}s)"
            fi
          done
          
          # 6. Check for common GCP Load Balancer issues
          echo ""
          echo "üîç 6. GCP LOAD BALANCER DIAGNOSTICS:"
          echo "===================================="
          
          # Check if services have proper annotations
          echo "üìã Service Annotations Check:"
          for service in auth-service text-extraction-service text-summarization-service; do
            echo "  Checking $service annotations..."
            kubectl get service $service -n doc-intel-app -o jsonpath='{.metadata.annotations}' | python3 -c 'import sys, json; input_data = sys.stdin.read().strip(); data = json.loads(input_data) if input_data else {}; print(f"    NEG: {data.get(\"cloud.google.com/neg\", \"MISSING\")}"); print(f"    BackendConfig: {data.get(\"cloud.google.com/backend-config\", \"MISSING\")}")' || echo "    Service not found or no annotations"
          done
          
          # 7. Final status summary
          echo ""
          echo "üìä 7. FINAL STATUS SUMMARY:"
          echo "=========================="
          echo "üèóÔ∏è  Deployments: $(kubectl get deployments -n doc-intel-app --no-headers | wc -l) total"
          echo "üè• Ready Pods: $(kubectl get pods -n doc-intel-app --no-headers | grep -c Running) running"
          echo "üåê Services: $(kubectl get services -n doc-intel-app --no-headers | wc -l) total"
          echo "üîó Ingress IP: $INGRESS_IP"
          
          # Check if any pods are not ready
          not_ready=$(kubectl get pods -n doc-intel-app --no-headers | grep -v "1/1.*Running" | wc -l)
          if [ $not_ready -gt 0 ]; then
            echo "‚ö†Ô∏è  Warning: $not_ready pods are not ready"
            kubectl get pods -n doc-intel-app | grep -v "1/1.*Running" || true
          fi

      - name: Get deployment status
        run: |
          echo "=== Backend Services Status ==="
          kubectl get deployments --namespace=doc-intel-app
          echo ""
          echo "=== Frontend Cloud Run Status ==="
          gcloud run services describe frontend --region=${{ env.REGION }} --format="value(status.url)"
